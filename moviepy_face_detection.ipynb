{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f265a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from moviepy.editor import *\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "from numpy import asarray\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0e356c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change ffmpeg used by moviepy to the one installed if one is installed, otherwise use the one from moviepy.\n",
    "# This is necessary for using HW acceleration.\n",
    "try:\n",
    "    from moviepy.config import change_settings\n",
    "    change_settings({\"FFMPEG_BINARY\":\"ffmpeg\"})\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f2c3f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be empty if the video file and its videopipe output are at the same\n",
    "# location as the code\n",
    "path = ''\n",
    "v_name = 'HIGH_LIGHTS_I_SNOWMAGAZINE_I_SANDER_26'\n",
    "task = '_frame_face_detection_datamodel'\n",
    "w, h = 1920, 1080\n",
    "RESIZE_DIM = 640"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63283a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## read face detection json\n",
    "\n",
    "faces = pd.read_json(path + v_name + '/' + v_name + task + '.json', lines = True)\n",
    "\n",
    "faces_detected = [f for f in faces.data[0] if len(f['faces']) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "607255bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Writing audio in HIGH_LIGHTS_I_SNOWMAGAZINE_I_SANDER_26_audio.mp3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                        "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "## read video file with moviepy\n",
    "clip = VideoFileClip(v_name + '.mp4')\n",
    "audio = clip.audio\n",
    "\n",
    "# Write audio to file\n",
    "audio.write_audiofile(v_name + '_audio.mp3')\n",
    "\n",
    "fps = clip.fps\n",
    "frame_duration = 1 / fps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b189456",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(clip, frame_number):\n",
    "    return Image.fromarray(clip.get_frame(frame_number * frame_duration))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a14bcd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw bounding box on each frame with a detected face, since images are\n",
    "# resized, we need to scale the bounding box coordinates.\n",
    "def draw_bounding_boxes(face, img, width_ratio, height_ratio):\n",
    "    for i in range(len(face['faces'])):\n",
    "        y0, x1, y1, x0 = face['faces'][i]['bb_faces']\n",
    "        y0 = int(y0 * height_ratio)\n",
    "        y1 = int(y1 * height_ratio)\n",
    "        x0 = int(x0 * width_ratio)\n",
    "        x1 = int(x1 * width_ratio)\n",
    "\n",
    "        draw = ImageDraw.Draw(img)\n",
    "        draw.rectangle([x0, y0, x1, y1], outline='red')\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d15bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set how many faces to be included in each video clip. If set to -1, all faces\n",
    "# will be included in one video clip. A lower number will result in more video\n",
    "# clips using less memory but more disk space. A higher number will result in\n",
    "# less video clips using more memory but less disk space. Also depends on how\n",
    "# many faces are detected in the video.\n",
    "faces_limit = 100\n",
    "\n",
    "duration_t = frame_duration\n",
    "prev_t = 0\n",
    "\n",
    "f = open('face_detection.txt', 'w')\n",
    "\n",
    "def get_face_clips(faces_detected, faces_limit=100, timestamp=0):\n",
    "    clips = []\n",
    "    face_count = 0\n",
    "    for face in faces_detected:\n",
    "        if face_count == faces_limit:\n",
    "            break\n",
    "\n",
    "        img = get_frame(clip, face['dimension_idx'])\n",
    "        t = face['dimension_idx'] * frame_duration\n",
    "\n",
    "        w, h = img.size\n",
    "        width_ratio = w / RESIZE_DIM\n",
    "        height_ratio = h / RESIZE_DIM\n",
    "\n",
    "        draw_bounding_boxes(face, img, width_ratio, height_ratio)\n",
    "\n",
    "        if (timestamp != t):\n",
    "            clips.append(clip.subclip(timestamp, t))\n",
    "        clips.append(ImageClip(asarray(img), duration=duration_t))\n",
    "        img.close()\n",
    "        timestamp = t + duration_t\n",
    "        face_count += 1\n",
    "\n",
    "        # Add final clip if it is the last face.\n",
    "        if face == faces_detected[-1]:\n",
    "            clips.append(clip.subclip(timestamp, clip.duration))\n",
    "            timestamp = clip.duration\n",
    "\n",
    "    return clips, timestamp\n",
    "\n",
    "# Create video clips with detected faces and concatenate them into one video.\n",
    "for i in range(len(faces_detected) // faces_limit + 1):\n",
    "    clips = []\n",
    "    clips, prev_t = get_face_clips(faces_detected[i * faces_limit:], faces_limit, prev_t)\n",
    "\n",
    "    # Try hw acceleration, else use cpu.\n",
    "    try:\n",
    "        concatenate_videoclips(clips).write_videofile('face_detection_' + str(i) + '.mp4', codec='h264_nvenc', fps=fps, logger=None, audio=False, preset='3')\n",
    "    except:\n",
    "        try:\n",
    "            concatenate_videoclips(clips).write_videofile('face_detection_' + str(i) + '.mp4', codec='libx264', fps=fps, logger=None, audio=False)\n",
    "        except:\n",
    "            raise Exception('An error occured while writing the video file.')\n",
    "    f.write('file face_detection_' + str(i) + '.mp4\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cf7b8648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any existing output.mp4 file\n",
    "if os.path.exists('output.mp4'):\n",
    "    os.remove('output.mp4')\n",
    "if os.path.exists(v_name + '_face_detection.mp4'):\n",
    "    os.remove(v_name + '_face_detection.mp4')\n",
    "\n",
    "# Concatenate all the files in the face_detection.txt file into one final clip\n",
    "# and write to .mp4 file.\n",
    "subprocess.call(\"ffmpeg -f concat -safe 0 -i face_detection.txt -c copy output.mp4\", shell=True)\n",
    "\n",
    "# Add audio to the final clip.\n",
    "subprocess.call(\"ffmpeg -i output.mp4 -i \" + v_name + \"_audio.mp3 -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest \" + v_name + \"_face_detection.mp4\", shell=True)\n",
    "\n",
    "# Delete all the subclips.\n",
    "for i in range(len(faces_detected) // faces_limit + 1):\n",
    "    os.remove('face_detection_' + str(i) + '.mp4')\n",
    "\n",
    "# Delete the face_detection.txt file.\n",
    "os.remove('face_detection.txt')\n",
    "\n",
    "# Delete the audio file.\n",
    "os.remove(v_name + '_audio.mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
