{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ff9198",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from moviepy.editor import *\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import os\n",
    "import subprocess"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "559304d8",
   "metadata": {},
   "source": [
    "Names of path, videofile and type of JSON. Path can be empty if the video file and its videopipe output are at the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4aff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = ''\n",
    "video_path = 'Videos/'\n",
    "v_name = 'D9003811_RUNNING_JEAN-PIERRE'\n",
    "task = '_face_detection_datamodel'\n",
    "RESIZE_DIM = 640"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "63ae5a8c",
   "metadata": {},
   "source": [
    "Read face detection json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d68ce12",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces = pd.read_json(f\"{path + v_name}/{v_name + task}.json\", lines=True)\n",
    "faces_detected = [f for f in faces.data[0] if len(f['faces']) > 0]\n",
    "v_name = video_path + v_name"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d74acb86",
   "metadata": {},
   "source": [
    "Read video file with moviepy and write audio to a seperate file for later use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "240e306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip = VideoFileClip(v_name + '.mp4')\n",
    "audio = clip.audio\n",
    "audio.write_audiofile(v_name + '_audio.mp3')\n",
    "\n",
    "fps = clip.fps\n",
    "frame_duration = 1 / fps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "165dd68e",
   "metadata": {},
   "source": [
    "Play a subclip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ca1be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#clip.subclip(t_start=0*frame_duration,\n",
    "#             t_end=5*frame_duration).ipython_display()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "157b39d4",
   "metadata": {},
   "source": [
    "Get the frame of the frame number provided. MoviePy gets frames by their timestap so we first convert the frame number to this.\n",
    "\n",
    "If get_frame gives an OSError, make sure you have the right moviepy version (especially on Linux): \\\n",
    "pip uninstall moviepy \\\n",
    "pip install moviepy==2.0.0.dev2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ed3b191",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame_by_number(clip, frame_number):\n",
    "    \"\"\" Returns the frame from the clip by their frame_number. \"\"\"\n",
    "    \n",
    "    frame_duration = 1 / clip.fps\n",
    "    frame = clip.get_frame(frame_number * frame_duration)\n",
    "    return Image.fromarray(frame)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d877ff75",
   "metadata": {},
   "source": [
    "Scale the bounding box coordinates to the image dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f029e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_bb_to_image(y0, x1, y1, x0):\n",
    "    \"\"\" Scales a bounding box to the image using the global RESIZE_DIM variable. \"\"\"\n",
    "\n",
    "    w, h = clip.size\n",
    "    width_ratio = w / RESIZE_DIM\n",
    "    height_ratio = h / RESIZE_DIM\n",
    "\n",
    "    y0 = int(y0 * height_ratio)\n",
    "    y1 = int(y1 * height_ratio)\n",
    "    x0 = int(x0 * width_ratio)\n",
    "    x1 = int(x1 * width_ratio)\n",
    "    \n",
    "    return [x0, y0, x1, y1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9317a995",
   "metadata": {},
   "source": [
    "Draw the bounding box on top of the image of the detected face. From the PIL documentation: Sequence of either [(x0, y0), (x1, y1)] or [x0, y0, x1, y1], where x1 >= x0 and y1 >= y0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec725aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_box(img, x0, y0, x1, y1):\n",
    "    \"\"\" Draw a bounding box (consisting of the points x0, y0, x1, y1) on top of a frame. \"\"\"\n",
    "    copy = img.copy()\n",
    "    draw = ImageDraw.Draw(copy)\n",
    "    draw.rectangle([x0, y0, x1, y1], fill=None, outline='red', width=2)\n",
    "    return copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1399fcd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bounding_boxes(frame, faces):\n",
    "    \"\"\" Draw all the bounding boxes in the list of faces on top of the frame. \"\"\"\n",
    "    frame_copy = frame.copy()\n",
    "    for face in faces:\n",
    "        scaled_bb = scale_bb_to_image(*face['bb_faces'])\n",
    "        frame_copy = draw_bounding_box(frame_copy, *scaled_bb)\n",
    "    \n",
    "    return frame_copy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e0705834",
   "metadata": {},
   "source": [
    "Below we test the draw_bounding_boxes function on a frame with multiple detected faces in them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d15bed26",
   "metadata": {},
   "outputs": [],
   "source": [
    "mult_face_frames= [(face['dimension_idx'], face) for face in faces_detected if len(face['faces']) > 1]\n",
    "\n",
    "mult_face_frames\n",
    "\n",
    "face_frame, faces_to_draw = mult_face_frames[0]\n",
    "\n",
    "first_face = get_frame_by_number(clip, face_frame)\n",
    "\n",
    "bb_frame = draw_bounding_boxes(first_face, faces_to_draw['faces'])\n",
    "display(bb_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35338f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_frame(clip, faces):\n",
    "    \"\"\" Draw the faces on top of the frame in 'clip' and also return the corresponding frame timestamp. \"\"\"\n",
    "    face_frame_number = faces['dimension_idx']\n",
    "    face_timestamp = face_frame_number / clip.fps\n",
    "    frame = get_frame_by_number(clip, face_frame_number)\n",
    "    bb_frame = draw_bounding_boxes(frame, faces['faces'])\n",
    "\n",
    "    return face_timestamp, bb_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d330e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_face_clips(clip, faces_detected, face_frame_duration, timestamp_offset=0):\n",
    "    \"\"\" Make a list of clips with all the face frames in 'faces_detected' inserted in 'clip'. \n",
    "    face_frames are inserted with a duration of 'face_frame_duration'.\n",
    "    'timestamp_offset' is used to determine the starting time of the first (faceless) subclip.\n",
    "    \"\"\"\n",
    "\n",
    "    clips = []\n",
    "    for faces in faces_detected:\n",
    "        ts, bb_frame = make_frame(clip, faces)\n",
    "\n",
    "        if (timestamp_offset != ts):\n",
    "            clips.append(clip.subclip(timestamp_offset, ts))\n",
    "\n",
    "        face_frame_clip = ImageClip(np.asarray(bb_frame), duration=face_frame_duration)\n",
    "        clips.append(face_frame_clip)\n",
    "        timestamp_offset = ts + face_frame_duration\n",
    "\n",
    "    return clips, timestamp_offset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9bee0bfa",
   "metadata": {},
   "source": [
    "Now we write videofiles containing faces_per_round amount of faces. We also add the name of the videofile to a txt file so we can later concatenate these together again. We split the writing of video clips in multiple rounds to save on memory usage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761a4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "faces_per_round = 100\n",
    "face_frame_duration = frame_duration\n",
    "prev_ts = 0\n",
    "\n",
    "f = open('face_detection.txt', 'w')\n",
    "\n",
    "# Create video clips with 'faces_per_round' amount of detected faces inserted per clip. \n",
    "for round in range(len(faces_detected) // faces_per_round + 1):\n",
    "    clips = []\n",
    "    start_face_number = round * faces_per_round\n",
    "    end_face_number = start_face_number + faces_per_round\n",
    "    face_batch = faces_detected[start_face_number:end_face_number]\n",
    "    clips, prev_ts = get_face_clips(clip, face_batch, face_frame_duration, prev_ts)\n",
    "\n",
    "    concatenate_videoclips(clips).write_videofile('face_detection_' + str(round) + '.mp4', codec='libx264', fps=fps, logger=None, audio=False)\n",
    "    f.write('file face_detection_' + str(round) + '.mp4\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17667d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove any existing output.mp4 file\n",
    "if os.path.exists('output.mp4'):\n",
    "    os.remove('output.mp4')\n",
    "if os.path.exists(v_name + '_face_detection.mp4'):\n",
    "    os.remove(v_name + '_face_detection.mp4')\n",
    "\n",
    "# Concatenate all the files in the face_detection.txt file into one final clip\n",
    "# and write to .mp4 file.\n",
    "subprocess.call(\"ffmpeg -f concat -safe 0 -i face_detection.txt -c copy output.mp4\", shell=True)\n",
    "\n",
    "# Add audio to the final clip.\n",
    "subprocess.call(\"ffmpeg -i output.mp4 -i \" + v_name + \"_audio.mp3 -c:v copy -c:a aac -map 0:v:0 -map 1:a:0 -shortest \" + v_name + \"_face_detection.mp4\", shell=True)\n",
    "\n",
    "# Delete all the subclips.\n",
    "for round in range(len(faces_detected) // faces_per_round + 1):\n",
    "    os.remove('face_detection_' + str(round) + '.mp4')\n",
    "\n",
    "# Delete the face_detection.txt file.\n",
    "os.remove('face_detection.txt')\n",
    "\n",
    "# Delete the audio file.\n",
    "os.remove(v_name + '_audio.mp3')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
