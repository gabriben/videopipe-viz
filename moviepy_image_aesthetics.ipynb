{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from moviepy.editor import *\n",
    "from PIL import Image\n",
    "from PIL import ImageDraw\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this can be empty if the video file and its videopipe output are at the same\n",
    "# location as the code\n",
    "path = ''\n",
    "v_name = 'HIGH_LIGHTS_I_SNOWMAGAZINE_I_SANDER_26'\n",
    "task = '_image_aesthetics_datamodel'\n",
    "w, h = 1920, 1080"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read shots detection json\n",
    "\n",
    "aesthetics = pd.read_json(path + v_name + '/' + v_name + task + '.json', lines = True)\n",
    "aesthetics_detected = [f for f in aesthetics.data[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read video file\n",
    "\n",
    "clip = VideoFileClip(v_name + '.mp4')\n",
    "\n",
    "fps = clip.fps\n",
    "frame_duration = 1 / fps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set n to how many frames the top frames should consist of."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the amount of frames\n",
    "n = 10"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the top n aesthetics frames and the top n technical frames, ordered from lowest to highest. Also get the top frames for both aesthetics and technical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 aesthetics frames:  [4186, 4004, 2184, 2002, 5096, 13832, 2366, 3276, 3094, 4368]\n",
      "Top 10 technical frames:  [4368, 6916, 6552, 4550, 8190, 9464, 7462, 7826, 6188, 10374]\n",
      "Top 10 both frames:  [4914, 9464, 6916, 16016, 6188, 4186, 2002, 8190, 4550, 4368]\n"
     ]
    }
   ],
   "source": [
    "## Get 2n frames from aesthetics_detected, n with the highest aesthetics score and n with the highest technical score.\n",
    "\n",
    "highest_aesthetics = sorted(aesthetics_detected, key = lambda x: x['aesthetics_score'], reverse = True)\n",
    "highest_technical = sorted(aesthetics_detected, key = lambda x: x['technical_score'], reverse = True)\n",
    "\n",
    "# Get highest of both.\n",
    "highest = sorted(aesthetics_detected, key = lambda x: x['aesthetics_score'] + x['technical_score'], reverse = True)\n",
    "\n",
    "# Top frames from lowest to highest\n",
    "top_aesthetics = [f['dimension_idx'] for f in reversed(highest_aesthetics[:n])]\n",
    "top_technical = [f['dimension_idx'] for f in reversed(highest_technical[:n])]\n",
    "top_both = [f['dimension_idx'] for f in reversed(highest[:n])]\n",
    "\n",
    "print('Top ' + str(n) + ' aesthetics frames: ', top_aesthetics)\n",
    "print('Top ' + str(n) + ' technical frames: ', top_technical)\n",
    "print('Top ' + str(n) + ' both frames: ', top_both)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_frame(clip, frame_number):\n",
    "    return Image.fromarray(clip.get_frame(frame_number * frame_duration))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create image clips which are prefixed with a textclips showing the ranking of the frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set duration of frame.\n",
    "duration_f = 3\n",
    "\n",
    "# Set duration of text\n",
    "duration_t = 1\n",
    "\n",
    "\n",
    "aesthetics_clips = []\n",
    "technical_clips = []\n",
    "both_clips = []\n",
    "\n",
    "# Create the list of textclips and imageclips.\n",
    "def subclips(top, duration_fr, duration_txt, count):\n",
    "    clips = []\n",
    "    for f in top:\n",
    "        txtclip = TextClip('Frame ' + str(count), fontsize = 50, color = 'white', size=(w,h)).set_duration(duration_txt)\n",
    "        frame = get_frame(clip, f)\n",
    "        imgclip = ImageClip(np.asarray(frame), duration = duration_fr)\n",
    "        clips.append(txtclip)\n",
    "        clips.append(imgclip)\n",
    "        count -= 1\n",
    "    return clips\n",
    "\n",
    "aesthetics_clips = subclips(top_aesthetics, duration_f, duration_t, n)\n",
    "technical_clips = subclips(top_technical, duration_f, duration_t, n)\n",
    "both_clips = subclips(top_both, duration_f, duration_t, n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the gifs, fps can be set to 1 to improve performance since we only show still images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file aesthetics.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file technical.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Building file both.gif with imageio.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                            \r"
     ]
    }
   ],
   "source": [
    "final_aesthetics = concatenate_videoclips(aesthetics_clips)\n",
    "final_technical = concatenate_videoclips(technical_clips)\n",
    "final_both = concatenate_videoclips(both_clips)\n",
    "\n",
    "final_aesthetics.write_gif(\"aesthetics.gif\", fps=1)\n",
    "final_technical.write_gif(\"technical.gif\", fps=1)\n",
    "final_both.write_gif(\"both.gif\", fps=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
